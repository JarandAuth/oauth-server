spring.application.name=oauth-server
# Server
server.port=8080
server.servlet.context-path=/v0/${spring.application.name}
server.http2.enabled=true
server.compression.enabled=true
# Monitoring
management.endpoints.web.exposure.include=health,prometheus
management.endpoint.health.probes.enabled=true
management.prometheus.metrics.export.enabled=true
# Logging
logging.level.org.apache.kafka.clients.producer.ProducerConfig=WARN
logging.level.org.apache.kafka.clients.consumer.ConsumerConfig=WARN
logging.level.org.apache.kafka.clients.admin.AdminClientConfig=WARN
# Kafka common
spring.kafka.bootstrap-servers=localhost:9091
spring.kafka.security.protocol=PLAINTEXT
kafka.partitions=2
kafka.replicas=2
# Kafka producer
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.acks=1
spring.kafka.producer.properties.enable.idempotence=false
# Kafka consumer
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.group-id=DEV.${spring.application.name}
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.listener.ack-mode=manual_immediate
spring.kafka.listener.concurrency=${kafka.partitions}
# Kafka topics
raw-events.topic-name=DEV.${spring.application.name}.raw-events
raw-events.partitions=${kafka.partitions}
raw-events.replicas=${kafka.replicas}
# Database
spring.datasource.url=jdbc:postgresql://localhost:5432/${spring.application.name}-dev-db
spring.datasource.username=${spring.application.name}-dev-dbo
spring.datasource.password=postgres
# Documentation
springdoc.show-actuator=true
springdoc.swagger-ui.operations-sorter=alpha
springdoc.swagger-ui.tags-sorter=alpha
